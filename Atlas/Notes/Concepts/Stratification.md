---
created: 2024-09-19
up: "[[Concepts]]"
source: "[[The Art of Statistics]]"
---

Stratification refers to dividing a population or dataset into distinct groups, or "strata", based on certain characteristics. These groups are made so that the individuals within each stratum are more similar to each other in terms of a specific variable, while they might be quite different from individuals in other strata. 

For example, suppose you are studying the average income of a population. You might "stratify" the population by age groups or education levels, because income is likely to vary within these categories. So, you would separate your dataset into different strata (e.g., 18-25 years, 26-35 years, etc.) and then analyze each group separately or combine them in a meaningful way later. 

Stratification is useful because:
- Improved accuracy - by ensuring that comparisons are made within more homogeneous groups, stratification can reduce variability and lead to more precise estimates or conclusions. 
- Controlling for confounding - in cases where certain variables might influence your results, stratifying by those variables helps to control their effects and avoid misleading conclusions. 
- Representative samples - ensures that important subgroups are not overlooked, providing a more accurate reflection of the entire population.
- Efficient analysis - allows for targeted analysis of specific groups, which can reveal insights that might be missed in a general study. 

Stratification helps you compare "like with like" in statistical analysis. It prevents one group's characteristics from unfairly influencing the results of another. 

For example, in a clinical study, stratifying by age or gender ensures that comparisons of treatment effects are fair across different groups. 